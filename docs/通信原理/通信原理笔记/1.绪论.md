# 绪论

## 信息及其度量

> [!IMPORTANT]
>
> 假设 $P(x)$表示消息发生的概率, $I$ 表示消息中所含的**信息量**
> $$
> I=\log_a\frac{1}{P(x)}=-\log_aP(x)
> $$
> 定义平均信息量,或者**信息源的熵**为
> $$
> \begin{aligned}H(x) & =P(x_1)\left[-\log_2P(x_1)\right]+P(x_2)\left[-\log_2P(x_2)\right]+\cdots+P(x_{M})\left[-\log_2P(x_{M})\right]\\  
> & =-\sum_{i=1}^{M}P(x_{i})\log_2P(x_{i})
> \end{aligned}
> $$
>

可以发现:

1. 等概率时,有**最大信息熵**
2. 等概率时,每个二进制波形含1bit的信息量,信源的熵等于每个符号的信息量
3. 非等概率时,概率越小的符号,其信息量越大



## 通信系统主要性能指标

1. 有效性

频带利用率
$$
\eta=\frac{R_\mathrm{B}}{B}
$$
或
$$
\eta_\mathrm{b}=\frac{R_\mathrm{b}}{B}
$$

其中$R_\mathrm{B}$为码元传输效率（波特率），$R_\mathrm{b}$为信息传输效率（比特率）
$$
R_{B}=\frac{1}{T_{B}}
$$
在$M$进制码元中
$$
R_{\mathrm{b}}=R_{\mathrm{B}}\log_{2}M
$$

同时也有
$$
R_{b}=R_{B}\cdot H
$$



2. 可靠性

误码率$P_{e}$
$$
P_{\mathrm{e}}=\frac{\text{错误码元数}}{\text{传输总码元数}}
$$
误信率$P_{\mathrm{b}}$
$$
P_{\mathrm{b}}=\frac{\text{错误比特数}}{\text{传输总比特数}}
$$
在二进制中
$$
P_{\mathrm{b}}=P_{\mathrm{e}}
$$
